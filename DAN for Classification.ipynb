{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAN Overview\n",
    "\n",
    "The Deep Averaging Network is a relatively simple, but effective, network for text classification.  This model \n",
    "seeks to take the average word embedding for a document, and pass it through a couple non-linearity layers for \n",
    "final classification.\n",
    "\n",
    "**Note** Unfortunately due to class imbalance and other issues I was unable to get this model to produce useful results.  It's possible it could get better results by allowing training on the word embeddings but with the size of the pre-trained vectors this is extremely time consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in doc metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}\n",
    "with open(\"data/lit-review-doc-metadata.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        docs[row[\"Document Title\"]] = row\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 296 docs\n"
     ]
    }
   ],
   "source": [
    "not_found = 0\n",
    "with open(\"data/lit-review-categories.csv\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row[\"Document Title\"] in docs:\n",
    "            docs[row[\"Document Title\"]][\"Label\"] = row[\"Domain\"]\n",
    "        else:\n",
    "            not_found += 1\n",
    "#             print(\"missing: {}\".format(row[\"Document Title\"]))\n",
    "\n",
    "print(\"Missing {} docs\".format(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439 9439\n"
     ]
    }
   ],
   "source": [
    "abstracts = [d[\"Abstract\"] for d in docs.values() if \"Label\" in d]\n",
    "labels = [d[\"Label\"] for d in docs.values() if \"Label\" in d]\n",
    "print(len(abstracts), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prebuilt word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/GoogleNews-vectors-negative300.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "word2ind = {k: v.index for k,v in word_vectors.vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = \"sgsma-topics-dan.pt\"\n",
    "grad_clipping = 5\n",
    "checkpoint = 100\n",
    "batch_size = 16\n",
    "device = \"cpu\"\n",
    "\n",
    "class DanModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes, n_hidden_units=50, nn_dropout=.5):\n",
    "        super(DanModel, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.nn_dropout = nn_dropout\n",
    "        \n",
    "        self.vocab_size, self.emb_dim = word_vectors.vectors.shape\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(word_vectors.vectors))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        self.linear1 = nn.Linear(self.emb_dim, n_hidden_units)\n",
    "        self.linear2 = nn.Linear(n_hidden_units, n_classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.linear1,\n",
    "            nn.ReLU(),\n",
    "            self.linear2)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_text, text_len):\n",
    "        # get word embeddings\n",
    "        text_embed = self.embeddings(input_text)\n",
    "\n",
    "        # calculate the mean embeddings\n",
    "        encoded = text_embed.sum(1)\n",
    "        encoded /= text_len.view(text_embed.size(0), -1)\n",
    "\n",
    "        # run data through the classifier\n",
    "        logits = self.classifier(encoded)\n",
    "\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abstract_Dataset(Dataset):\n",
    "    def __init__(self, examples, vobab):\n",
    "        self.examples = examples\n",
    "        self.word2ind = word2ind\n",
    "    def __getitem__(self, index):\n",
    "        return vectorize(self.examples[index], self.word2ind)\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "\n",
    "def vectorize(ex, word2ind):\n",
    "    abstract_text, abstract_label = ex\n",
    "    vec_text = [0] * len(abstract_text)\n",
    "    for idx, token in enumerate(abstract_text):\n",
    "        if token in word2ind:\n",
    "            vec_text[idx] = word2ind[token]\n",
    "    return vec_text, abstract_label\n",
    "\n",
    "\n",
    "def batchify(batch):\n",
    "    abstract_len = list()\n",
    "    label_list = list()\n",
    "    for ex in batch:\n",
    "        abstract_len.append(len(ex[0]))\n",
    "        label_list.append(ex[1])\n",
    "    target_labels = torch.LongTensor(label_list)\n",
    "    x1 = torch.LongTensor(len(abstract_len), max(abstract_len)).zero_()\n",
    "    for i in range(len(abstract_len)):\n",
    "        abstract_text = batch[i][0]\n",
    "        vec = torch.LongTensor(abstract_text)\n",
    "        x1[i, :len(abstract_text)].copy_(vec)\n",
    "    q_batch = {'text': x1, 'len': torch.FloatTensor(abstract_len), 'labels': target_labels}\n",
    "    return q_batch        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data_loader, dev_data_loader, accuracy, device):\n",
    "    \"\"\"\n",
    "    Train the current model\n",
    "\n",
    "    Keyword arguments:\n",
    "    model: model to be trained\n",
    "    train_data_loader: pytorch build-in data loader output for training examples\n",
    "    dev_data_loader: pytorch build-in data loader output for dev examples\n",
    "    accuracy: previous best accuracy\n",
    "    device: cpu of gpu\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adamax(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print_loss_total = 0\n",
    "    epoch_loss_total = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for idx, batch in enumerate(train_data_loader):\n",
    "        abstract_text = batch['text'].to(device)\n",
    "        abstract_len = batch['len']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        output = model(abstract_text, abstract_len)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        clip_grad_norm_(model.parameters(), grad_clipping)\n",
    "        print_loss_total += loss.data.numpy()\n",
    "        epoch_loss_total += loss.data.numpy()\n",
    "\n",
    "        if idx % checkpoint == 0 and idx > 0:\n",
    "            print_loss_avg = print_loss_total / checkpoint\n",
    "\n",
    "            print('number of steps: %d, loss: %.5f time: %.5f' % (idx, print_loss_avg, time.time()- start))\n",
    "            print_loss_total = 0\n",
    "            curr_accuracy = evaluate(dev_data_loader, model, device)\n",
    "            if accuracy < curr_accuracy:\n",
    "                torch.save(model, save_model)\n",
    "                accuracy = curr_accuracy\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate(data_loader, model, device):\n",
    "    \"\"\"\n",
    "    evaluate the current model, get the accuracy for dev/test set\n",
    "\n",
    "    Keyword arguments:\n",
    "    data_loader: pytorch data loader output\n",
    "    model: model to be evaluated\n",
    "    device: cpu or gpu\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_examples = 0\n",
    "    error = 0\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        abstract_text = batch['text'].to(device)\n",
    "        abstract_len = batch['len']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = model(abstract_text, abstract_len)\n",
    "\n",
    "        top_n, top_i = logits.topk(1)\n",
    "        num_examples += abstract_text.size(0)\n",
    "        error += torch.nonzero(top_i.squeeze() - torch.LongTensor(labels)).size(0)\n",
    "\n",
    "    accuracy = 1 - error / num_examples\n",
    "    print('accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Test, Dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ignore = (\"\", \"Overview\", \"Exclude\")\n",
    "corpus = [(d[\"Abstract\"].split(), d[\"Label\"]) for d in docs.values() if \"Label\" in d and d[\"Label\"] not in ignore] \n",
    "random.shuffle(corpus)\n",
    "\n",
    "category_lookup = {val: idx for idx, val in enumerate(set([d[1] for d in corpus]))}\n",
    "corpus = [(item[0], category_lookup[item[1]]) for item in corpus]\n",
    "\n",
    "\n",
    "dev_exs = corpus[:500]\n",
    "test_exs = corpus[500:1500]\n",
    "train_exs = corpus[1500:]\n",
    "\n",
    "train_dataset = Abstract_Dataset(train_exs, word2ind)\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=0, collate_fn=batchify)\n",
    "\n",
    "dev_dataset = Abstract_Dataset(dev_exs, word2ind)\n",
    "dev_sampler = torch.utils.data.sampler.SequentialSampler(dev_dataset)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size,\n",
    "    sampler=dev_sampler, num_workers=0, collate_fn=batchify)\n",
    "\n",
    "test_dataset = Abstract_Dataset(test_exs, word2ind)\n",
    "test_sampler = torch.utils.data.sampler.SequentialSampler(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "    sampler=test_sampler, num_workers=0, collate_fn=batchify)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DAN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DanModel(\n",
      "  (embeddings): Embedding(3000000, 300, padding_idx=0)\n",
      "  (linear1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (linear2): Linear(in_features=50, out_features=54, bias=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=54, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DanModel(len(category_lookup.keys()))\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0\n",
      "number of steps: 50, loss: 4.06700 time: 0.63172\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.98681 time: 5.76690\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.98511 time: 6.00155\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.98315 time: 6.24821\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.98102 time: 6.46715\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.97865 time: 6.70924\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 1\n",
      "number of steps: 50, loss: 4.05556 time: 0.15126\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.97408 time: 0.37651\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.97291 time: 0.61299\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.96973 time: 0.84011\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.96755 time: 1.08792\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.96428 time: 1.32841\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 2\n",
      "number of steps: 50, loss: 4.04297 time: 0.16256\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.96178 time: 0.38576\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.95941 time: 0.61289\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.95735 time: 0.84382\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.95466 time: 1.07344\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.95478 time: 1.30444\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 3\n",
      "number of steps: 50, loss: 4.03296 time: 0.15095\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.95193 time: 0.36263\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.94919 time: 0.59716\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.94975 time: 0.80882\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.95086 time: 1.03501\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.94749 time: 1.25203\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 4\n",
      "number of steps: 50, loss: 4.02746 time: 0.16395\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.94502 time: 0.39054\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.94058 time: 0.60493\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.94238 time: 0.81757\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.94312 time: 1.03662\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.94046 time: 1.26013\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 5\n",
      "number of steps: 50, loss: 4.01658 time: 0.14075\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.93674 time: 0.36286\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.93501 time: 0.59773\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.93957 time: 0.82241\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.93909 time: 1.06437\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.93702 time: 1.33226\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 6\n",
      "number of steps: 50, loss: 4.01722 time: 0.15956\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.93552 time: 0.38273\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92923 time: 0.60162\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.92727 time: 0.81464\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.92810 time: 1.04855\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.93084 time: 1.28262\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 7\n",
      "number of steps: 50, loss: 4.00480 time: 0.20288\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92464 time: 0.41828\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92697 time: 0.65459\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.93664 time: 0.89530\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.92863 time: 1.15720\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.92452 time: 1.38740\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 8\n",
      "number of steps: 50, loss: 4.00594 time: 0.14192\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92018 time: 0.37985\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.91919 time: 0.61890\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.92770 time: 0.83350\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.92729 time: 1.05412\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.93002 time: 1.26660\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 9\n",
      "number of steps: 50, loss: 4.00493 time: 0.15578\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92416 time: 0.37534\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92339 time: 0.66927\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.92526 time: 0.89078\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.92532 time: 1.14232\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.91690 time: 1.40066\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 10\n",
      "number of steps: 50, loss: 4.00980 time: 0.14582\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.91624 time: 0.35435\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.91992 time: 0.59280\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.92102 time: 0.83446\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.92302 time: 1.04617\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.90853 time: 1.24916\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 11\n",
      "number of steps: 50, loss: 3.99548 time: 0.17437\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.93511 time: 0.38293\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.91879 time: 0.60318\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.89629 time: 0.87112\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.90629 time: 1.15332\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.92534 time: 1.44967\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 12\n",
      "number of steps: 50, loss: 3.98896 time: 0.16046\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92941 time: 0.35523\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.90947 time: 0.60652\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.91401 time: 0.90262\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.90272 time: 1.12425\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.92819 time: 1.39253\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 13\n",
      "number of steps: 50, loss: 3.99209 time: 0.21342\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.91713 time: 0.48981\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92247 time: 0.76138\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.92045 time: 1.02710\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.91403 time: 1.28293\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.90556 time: 1.53896\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 14\n",
      "number of steps: 50, loss: 3.97472 time: 0.16788\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.90910 time: 0.40085\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92771 time: 0.70757\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.94019 time: 0.95617\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.89294 time: 1.18155\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.92641 time: 1.41428\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 15\n",
      "number of steps: 50, loss: 4.00566 time: 0.15174\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92402 time: 0.36932\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.91282 time: 0.60018\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.91032 time: 0.83444\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.91780 time: 1.05401\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.90780 time: 1.30451\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 16\n",
      "number of steps: 50, loss: 3.99697 time: 0.20654\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.90282 time: 0.44458\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.89283 time: 0.67656\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.93530 time: 0.90810\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.91655 time: 1.14874\n",
      "accuracy 0.09399999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of steps: 300, loss: 3.92780 time: 1.36770\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 17\n",
      "number of steps: 50, loss: 3.98696 time: 0.17345\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92281 time: 0.44832\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.89406 time: 0.68387\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.93780 time: 0.90512\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.91906 time: 1.12292\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.91281 time: 1.36123\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 18\n",
      "number of steps: 50, loss: 4.00071 time: 0.18926\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.91156 time: 0.43270\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.92031 time: 0.66161\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.91406 time: 0.90083\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.91531 time: 1.14497\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.91156 time: 1.36136\n",
      "accuracy 0.09399999999999997\n",
      "start epoch 19\n",
      "number of steps: 50, loss: 4.01571 time: 0.15246\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 100, loss: 3.92156 time: 0.39212\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 150, loss: 3.90656 time: 0.63091\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 200, loss: 3.91781 time: 0.90346\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 250, loss: 3.90281 time: 1.19570\n",
      "accuracy 0.09399999999999997\n",
      "number of steps: 300, loss: 3.91906 time: 1.47699\n",
      "accuracy 0.09399999999999997\n",
      "\n",
      "start testing:\n",
      "\n",
      "accuracy 0.08899999999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08899999999999997"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Training\n",
    "checkpoint = 50\n",
    "num_epochs = 20\n",
    "accuracy = 0\n",
    "\n",
    "# Train / Fit\n",
    "for epoch in range(num_epochs):\n",
    "    print('start epoch %d' % epoch)\n",
    "    accuracy = train(model, train_loader, dev_loader, accuracy, device)\n",
    "\n",
    "# Test\n",
    "print('\\nstart testing:\\n')\n",
    "evaluate(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsc723",
   "language": "python",
   "name": "cmsc723"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
